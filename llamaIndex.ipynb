{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex \n",
    "\n",
    "## 基本能力\n",
    "\n",
    "1. LLM 连接\n",
    "2. RAG 相关：Index，向量化，Query\n",
    "3. 复杂查询支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# 初始化 Ollama\n",
    "Settings.llm = Ollama(model='llama3.1:latest', base_url=\"http://localhost:6060\")\n",
    "\n",
    "\n",
    "# 创建一个 LlamaIndex 的聊天引擎\n",
    "chat_engine = SimpleChatEngine.from_defaults(llm=Settings.llm)\n",
    "response = chat_engine.chat(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/6tphk25x5kbgf_fkttqds14h0000gn/T/ipykernel_62581/3419600141.py:16: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(chunk_size_limit=1000,\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.core import Settings\n",
    "# from llama_index.settings import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, Settings\n",
    "\n",
    "# 初始化 Ollama\n",
    "Settings.llm = Ollama(model='llama3.1:latest', base_url=\"http://localhost:6060\", request_timeout=360.0)\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text:latest\", base_url=\"http://localhost:6060\")\n",
    "\n",
    "# Settings.llm = Ollama(model='llama3.1:latest', request_timeout=360.0)\n",
    "# Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text:latest\")\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=1000, \n",
    "    llm=Settings.llm, embed_model=Settings.embed_model)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=Settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately I don't have any information about someone named Paul Graham in this context. The text appears to be a personal account of someone's experiences with programming, computers, and artificial intelligence, but it doesn't mention Paul Graham or anything related to him. \n",
      "\n",
      "However, based on the provided information, we can see that the author went to college, studied philosophy, then switched to AI, and later focused on Lisp programming. The text also mentions that a book called \"On Lisp\" was written by this person during their time in grad school."
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode=\"condense_question\", streaming=True\n",
    ")\n",
    "response_stream = chat_engine.stream_chat(\"What did Paul Graham do after YC?\")\n",
    "response_stream.print_response_stream()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornell."
     ]
    }
   ],
   "source": [
    "response_stream = chat_engine.stream_chat(\"Paul Graham 上了哪所学校？\")\n",
    "response_stream.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
